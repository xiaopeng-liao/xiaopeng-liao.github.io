{
  "name": "Xiaopeng-liao.GitHub.io",
  "tagline": "Xiaopeng Liao's blog",
  "body": "# Welcome to Xiaopeng Liao's blog\r\nI am interesting in software design in general, love to try new ideas, currently into big data and machine learning technologies.\r\n\r\n## Spark Learning\r\nHere I will note down some learning encounter in Spark\r\n### [2016-09-21] How Spark handles the locality of the task\r\nI have been always wondering how Spark handles the locality of the task, how does it connects with RDD method \r\n` protected def getPreferredLocations(split: Partition): Seq[String] = Nil`\r\nIt turn out to be that when there is an operation on RDD, the DAG scheduler will look at the operation and then create a taskset, then submit to task scheduler, during sumbit, it will look at RDD's preferred location and put in different queue, later the scheduler will then assign node to execute the task based on this this. \r\n\r\nThe code looks like\r\n```\r\n   /**\r\n   * Dequeue a pending task for a given node and return its index and locality level.\r\n   * Only search for tasks matching the given locality constraint.\r\n   *\r\n   * @return An option containing (task index within the task set, locality, is speculative?)\r\n   */\r\n  private def dequeueTask(execId: String, host: String, maxLocality: TaskLocality.Value)\r\n    : Option[(Int, TaskLocality.Value, Boolean)] =\r\n  {\r\n    for (index <- dequeueTaskFromList(execId, getPendingTasksForExecutor(execId))) {\r\n      return Some((index, TaskLocality.PROCESS_LOCAL, false))\r\n    }\r\n\r\n    if (TaskLocality.isAllowed(maxLocality, TaskLocality.NODE_LOCAL)) {\r\n      for (index <- dequeueTaskFromList(execId, getPendingTasksForHost(host))) {\r\n        return Some((index, TaskLocality.NODE_LOCAL, false))\r\n      }\r\n    }\r\n\r\n    if (TaskLocality.isAllowed(maxLocality, TaskLocality.NO_PREF)) {\r\n      // Look for noPref tasks after NODE_LOCAL for minimize cross-rack traffic\r\n      for (index <- dequeueTaskFromList(execId, pendingTasksWithNoPrefs)) {\r\n        return Some((index, TaskLocality.PROCESS_LOCAL, false))\r\n      }\r\n    }\r\n\r\n    if (TaskLocality.isAllowed(maxLocality, TaskLocality.RACK_LOCAL)) {\r\n      for {\r\n        rack <- sched.getRackForHost(host)\r\n        index <- dequeueTaskFromList(execId, getPendingTasksForRack(rack))\r\n      } {\r\n        return Some((index, TaskLocality.RACK_LOCAL, false))\r\n      }\r\n    }\r\n\r\n    if (TaskLocality.isAllowed(maxLocality, TaskLocality.ANY)) {\r\n      for (index <- dequeueTaskFromList(execId, allPendingTasks)) {\r\n        return Some((index, TaskLocality.ANY, false))\r\n      }\r\n    }\r\n\r\n    // find a speculative task if all others tasks have been scheduled\r\n    dequeueSpeculativeTask(execId, host, maxLocality).map {\r\n      case (taskIndex, allowedLocality) => (taskIndex, allowedLocality, true)}\r\n  }\r\n```",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}